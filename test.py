
# í•„ìš” íŒ¨í‚¤ì§€ ì¶”ê°€
from generalmodule import combinedata, mergedata, insertdata, preprocessdata, encodingdata
from splitmodule1 import get_pattern, make_data
from splitmodule2 import splitdata
import time
import datetime
import pickle
import glob

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns

import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.metrics import f1_score, precision_score,recall_score,accuracy_score,confusion_matrix,classification_report
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBRFRegressor, XGBRFClassifier, XGBClassifier
import matplotlib.font_manager as fm

# í•œê¸€ê¹¨ì§ ë°©ì§€ì½”ë“œ 
font_location = '/home/sagemaker-user/gsc/NanumGothic.ttf'
fm.fontManager.addfont(font_location)
font_name = fm.FontProperties(fname=font_location).get_name()
matplotlib.rc('font', family=font_name)
matplotlib.rc('axes', unicode_minus=False)

# ì›¹ í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# page title: ë°ì´í„° ë¶„ì„ ë° ëª¨ë¸ë§ ëŒ€ì‹œë³´ë“œ
st.set_page_config(
    page_title="Priority opening fixed equipment", # page íƒ€ì´í‹€
    page_icon="ğŸ§Š", # page ì•„ì´ì½˜
    layout="wide", # wide, centered
    initial_sidebar_state="auto", # ì‚¬ì´ë“œ ë°” ì´ˆê¸° ìƒíƒœ
    menu_items={
        'Get Help': 'https://streamlit.io',
        'Report a bug': None,
        'About': '2023 GS CDS Class',

    }
)


import streamlit as st
import fitz
from PIL import Image
import io
import os

def pdf_to_images(pdf_path):
    pdf_document = fitz.open(pdf_path)
    images = []

    for page_number in range(pdf_document.page_count):
        # Get the page
        page = pdf_document[page_number]

        # Convert the page to a pixmap
        pixmap = page.get_pixmap()
        
#         img = img.resize((target_width, target_height))

        # Convert the pixmap to bytes using Pillow
        img = Image.frombytes("RGB", [pixmap.width, pixmap.height], pixmap.samples)
        img_bytes = io.BytesIO()
        img.save(img_bytes, format="PNG")
        images.append(img_bytes)

    pdf_document.close()
    return images

def front_page():
    # st.title("PDF Image Viewer")
    cols = st.columns((1, 1, 1))
    with cols[1]:
        st.write('Apps for')
    cols = st.columns((1, 4, 1))
    with cols[1]:
        st.subheader('**Considering Priority Opening Fixed Equipment**')
    cols = st.columns((1, 3, 1))
    with cols[1]:

        st.markdown("")
        st.divider()
        st.write(' 1. Preprocessing')
        # st.divider()
        st.write(' 2. EDA')
        # st.divider()
        st.write(' 3. Modeling')
        # st.divider()
        st.write(' 4. Model Serving')
        # st.divider()
        st.write(' 5. Result')
        st.divider()
        
        
    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
    script_directory = os.getcwd()
    pdf_path = os.path.join(script_directory, "GSCaltex_Signature_slogan.pdf")

    images = pdf_to_images(pdf_path)
    st.markdown("")
    st.markdown("")
    cols = st.columns((3, 3, 1))
    with cols[1]:
        st.write("By")
    # Display images in Streamlit
    for i, image in enumerate(images):
        st.image(image, use_column_width=True, width=100)

        
def file_merging():
    # íŒŒì¼ ì—…ë¡œë” ìœ„ì ¯ ì¶”ê°€ (1ë²ˆì¨°)
    file = st.file_uploader("Please upload PSM files", type=['csv', 'xls', 'xlsx'], accept_multiple_files=True)

    if file is not None:
        # ìƒˆ íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state['preprocessing_state'] = {}
        st.session_state['eda_state'] = {}
        st.session_state['modeling_state'] = {}
        st.session_state['serving_state'] = {}
        
        # ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
        st.session_state['preprocessing_state']['current_file'] = file
    
    # ìƒˆë¡œ ì—…ë¡œë“œí•œ íŒŒì¼ì„ dfë¡œ ë¡œë“œ
    if 'current_data' in st.session_state['preprocessing_state'] and len(st.session_state['preprocessing_state']['current_file']) > 0:
        if st.session_state['preprocessing_state']['current_data']:
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ì„ íƒ (ë¦¬ìŠ¤íŠ¸ì—ì„œ íŒŒì¼ì„ ì„ íƒí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½)
            selected_file = st.session_state['preprocessing_state']['current_data'][0]

            # íŒŒì¼ ì´ë¦„ ì¶œë ¥
            if hasattr(selected_file, 'name'):
                st.write(f"Current File: {selected_file.name}")
            else:
                st.write("Current File: Does not have 'name' attribute")

            # ì„ íƒëœ íŒŒì¼ì„ dfë¡œ ë¡œë“œ
            st.session_state['preprocessing_state']['current_data'] = load_file(selected_file)

    # # ìƒˆë¡œ ë¡œë“œí•œ df ì €ì¥
    # if 'current_data' in st.session_state['preprocessing_state']:
        # st.dataframe(st.session_state['preprocessing_state']['current_data'])
        
    if st.session_state['preprocessing_state']['current_file'] is not None and len(st.session_state['preprocessing_state']['current_file']) > 0:
        # ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ í•©ì³ì„œ DataFrameìœ¼ë¡œ ê°€ì ¸ì˜´
        
        combined_data = combinedata(st.session_state['preprocessing_state']['current_file'])

        # # ê²°ê³¼ë¥¼ í‘œì‹œ
        # st.dataframe(combined_data)
        
        # splitdata í•¨ìˆ˜ í˜¸ì¶œ
        df_split = splitdata(combined_data)
        st.session_state['preprocessing_state']['current_file'] = df_split
        st.session_state['preprocessing_state']['df_split'] = df_split
        # ê²°ê³¼ë¥¼ í‘œì‹œ
        # st.dataframe(df_split)
        
# files ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”
    files = []

    if 'current_file' in st.session_state['preprocessing_state'] and len(st.session_state['preprocessing_state']['current_file']) > 0:
        files = st.file_uploader("Please upload EPS files", type=['csv', 'xls', 'xlsx'], accept_multiple_files=True, key="file_uploader")

        # ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if files is not None:
            # ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            st.session_state['preprocessing_state']['current_file'] = files

            # ì—…ë¡œë“œëœ ê° íŒŒì¼ì„ ì½ì–´ DataFrameìœ¼ë¡œ ë³€í™˜
            dfs_uploaded = [pd.read_excel(file, header=None) for file in files]
            if len(dfs_uploaded) > 0:
                df_eps = dfs_uploaded[0]

                st.session_state['preprocessing_state']['current_data'] = df_eps

                # ìƒˆë¡œ ë¡œë“œí•œ df ì €ì¥
                if 'current_data' in st.session_state['preprocessing_state']:

                    df_eps = df_eps.rename(columns={0: 'ì¥ì¹˜ë²ˆí˜¸', 1: 'ì„¤ë¹„ë“±ê¸‰', 2:'ì„¤ë¹„ìœ í˜•',
                                                              6:'ë¶€ì‹ìœ¨', 7:'ì”ì—¬ìˆ˜ëª…'})
                    df_eps[15] = np.nan
                    df_eps[16] = np.nan
                    df_eps['ìš°ì„ ê°œë°©ì—¬ë¶€'] = 'í•´ë‹¹ì—†ìŒ'   
                    df_eps.columns = df_eps.columns.astype(str)
                    st.session_state['preprocessing_state']['eps_data'] = df_eps
                    # st.dataframe(st.session_state['preprocessing_state']['eps_data'])
                    # st.dataframe(st.session_state['preprocessing_state']['df_split'])
                    # df_aì™€ df_uploadedë¥¼ merge
                    df_merged = mergedata(st.session_state['preprocessing_state']['eps_data'], st.session_state['preprocessing_state']['df_split'])
                    st.session_state['preprocessing_state']['eps_data'] = df_merged
                    # st.dataframe(st.session_state['preprocessing_state']['eps_data'])
                    

    if 'eps_data' in st.session_state['preprocessing_state'] and len(st.session_state['preprocessing_state']['eps_data']) > 0:
        filess = st.file_uploader("Please upload EQL file", type=['csv', 'xls', 'xlsx'])

        # ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if filess is not None:
            # ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            st.session_state['preprocessing_state']['current_equlist'] = filess
            
        # ìƒˆë¡œ ì—…ë¡œë“œí•œ ì¥ì¹˜List íŒŒì¼ì„ dfë¡œ ë¡œë“œ
        if 'current_equlist' in st.session_state['preprocessing_state']:
            # st.write(f"Current File_equipment list: {st.session_state['preprocessing_state']['current_equlist'].name}")
            equlist = pd.read_excel(st.session_state['preprocessing_state']['current_equlist'], skiprows=1, engine='openpyxl')
            st.session_state['preprocessing_state']['equ_data'] = equlist
            df_final = insertdata(st.session_state['preprocessing_state']['equ_data'])
            st.session_state['preprocessing_state']['final_data'] = df_final
            st.dataframe(st.session_state['preprocessing_state']['final_data'])
                    
                
def file_preprocessing():
    if 'final_data' in st.session_state['preprocessing_state'] and len(st.session_state['preprocessing_state']['final_data']) > 0:     
        df_pre = preprocessdata(st.session_state['preprocessing_state']['final_data'])
        st.session_state['preprocessing_state']['complete_data'] = df_pre
        st.dataframe(st.session_state['preprocessing_state']['complete_data'])
    
        if 'complete_data' in st.session_state['preprocessing_state']:
        # 'ì¥ì¹˜ë²ˆí˜¸'ì™€ 'ì„¤ë¹„ìœ í˜•_ì¥ì¹˜List' ê°€ì ¸ì˜¤ê¸°
            filesss = st.file_uploader("Please upload priority opening equipment file", type=['csv', 'xls', 'xlsx'])

        # ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if filesss is not None:
                # ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
                st.session_state['preprocessing_state']['poe_data'] = filesss

            # ìƒˆë¡œ ì—…ë¡œë“œí•œ ì¥ì¹˜List íŒŒì¼ì„ dfë¡œ ë¡œë“œ
                if 'poe_data' in st.session_state['preprocessing_state']:
                    # st.write(f"Current File_equipment list: {st.session_state['preprocessing_state']['current_equlist'].name}")
                    poelist = pd.read_excel(st.session_state['preprocessing_state']['poe_data'],  engine='openpyxl')
                    st.session_state['preprocessing_state']['poe_data'] = poelist

                    # 'ì¥ì¹˜ë²ˆí˜¸'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ 'df_'ì™€ 'ì¥ì¹˜List' ë³‘í•©
                    poemerged_data = pd.merge(st.session_state['preprocessing_state']['complete_data'], st.session_state['preprocessing_state']['poe_data'], how='left', on='ì¥ì¹˜ë²ˆí˜¸')

                    # 'poelistì˜ ìš°ì„ ê°œë°©' ê°’ì„ 'completedataì˜ ìš°ì„ ê°œë°©ì—¬ë¶€'ì— ë®ì–´ì”Œìš°ê¸°
                    st.session_state['preprocessing_state']['complete_data']['ìš°ì„ ê°œë°©ì—¬ë¶€'] = poemerged_data['ìš°ì„ ê°œë°©']
                    st.session_state['preprocessing_state']['complete_data']['ìš°ì„ ê°œë°©ì—¬ë¶€'].fillna('í•´ë‹¹ì—†ìŒ', inplace=True)
                    st.dataframe(st.session_state['preprocessing_state']['complete_data'])
                    st.session_state['eda_state']['current_data'] = st.session_state['preprocessing_state']['complete_data']
        
def preprocessing_page():
    st.title('Preprocessing')
    
    # eda page tab ì„¤ì •
    # tabsì—ëŠ” File Upload, Variables (type, na, ë¶„í¬ ë“±), Correlation(ìˆ˜ì¹˜)ì´ í¬í•¨ë©ë‹ˆë‹¤.
    t1, t2 = st.tabs(['File Merging', 'File Preprocessing'])
    
    with t1:
        file_merging()
    
    with t2:
        file_preprocessing()
        
@st.cache_data
def load_file(file):
    
    # í™•ì¥ì ë¶„ë¦¬
    ext = file.name.split('.')[-1]
    
    # í™•ì¥ì ë³„ ë¡œë“œ í•¨ìˆ˜ êµ¬ë¶„
    if ext == 'csv':
        return pd.read_csv(file)
    elif 'xls' in ext:
        return pd.read_excel(file, engine='openpyxl')
        
# get_info í•¨ìˆ˜
@st.cache_data
def get_info(col, df):
    if col == 'ì¥ì¹˜ë²ˆí˜¸':
        return
    # ë…ë¦½ ë³€ìˆ˜ 1ê°œì˜ ì •ë³´ì™€ ë¶„í¬ figure ìƒì„± í•¨ìˆ˜
    plt.figure(figsize=(1.5,1))
    
    # ìˆ˜ì¹˜í˜• ë³€ìˆ˜(int64, float64)ëŠ” histogram : sns.histplot() ì´ìš©
    if df[col].dtype in ['int64','float64']:
        ax = sns.histplot(x=df[col], bins=30)
        plt.grid(False)
        print(df[col].dtype)
    # ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” seaborn.barplot ì´ìš©
    else:
        s_vc = df[col].value_counts().sort_index()
        ax = sns.barplot(x=s_vc.index, y=s_vc.values)

    plt.xlabel('')
    plt.xticks([])
    plt.ylabel('count')
    sns.despine(bottom = True, left = True)
    fig = ax.get_figure()
    
    # ì‚¬ì „ìœ¼ë¡œ ë¬¶ì–´ì„œ ë°˜í™˜
    return {'name': col, 'total': df[col].shape[0], 'na': df[col].isna().sum(), 'type': df[col].dtype, 'distribution':fig }

# variables í•¨ìˆ˜
def variables():
    # ê° ë³€ìˆ˜ ë³„ ì •ë³´ì™€ ë¶„í¬ figureë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    
    if 'current_data' in st.session_state['eda_state'] and len(st.session_state['eda_state']['current_data']) > 0:

        # ì €ì¥ëœ dfê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë™ì‘
        if 'current_data' in st.session_state['eda_state']:
            df = st.session_state['eda_state']['current_data']
            cols = df.columns

            # ì—´ ì •ë³´ë¥¼ ì²˜ìŒ ì €ì¥í•˜ëŠ” ê²½ìš° ì´ˆê¸° ì‚¬ì „ ìƒì„±
            if 'column_dict' not in st.session_state['eda_state']:
                st.session_state['eda_state']['column_dict'] = {}

            # ëª¨ë“  ì—´ì— ëŒ€í•œ ì •ë³´ ìƒì„± í›„ ì €ì¥
            for col in cols:
                st.session_state['eda_state']['column_dict'][col] = get_info(col, df)

            # ê° ì—´ì˜ ì •ë³´ë¥¼ í•˜ë‚˜ì”© ì¶œë ¥
            for col in st.session_state['eda_state']['column_dict']:
                print(f'=============325ë²ˆì§¸ì¤„ {df[col].dtype}')
                if col == 'ì¥ì¹˜ë²ˆí˜¸':
                    continue
                with st.expander(col, expanded=True):
                    left, right = st.columns((1, 1))
                    right.pyplot(st.session_state['eda_state']['column_dict'][col]['distribution'], use_container_width=True)
                    left.subheader(f"**:blue[{st.session_state['eda_state']['column_dict'][col]['name']}]**")
                    left.caption(st.session_state['eda_state']['column_dict'][col]['type'])
                    # cl, cr = center.columns(2)
                    # cl.markdown('**Missing**')
                    # cr.write(f"{st.session_state['eda_state']['column_dict'][col]['na']}")
                    # cl.markdown('**Missing Rate**')
                    # cr.write(f"{st.session_state['eda_state']['column_dict'][col]['na']/len(df):.2%}")
    else:
        st.warning('You should upload data')
                
# corr ê³„ì‚° í•¨ìˆ˜
@st.cache_data
def get_corr(options, df):
    # ì „ë‹¬ëœ ì—´ì— ëŒ€í•œ pairplot figure ìƒì„±
    pairplot = sns.pairplot(df, vars=options)
    return pairplot.fig
            
# correlation tab ì¶œë ¥ í•¨ìˆ˜
def correlation():
    cols = []
    
    # ì €ì¥ëœ dfê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ë™ì‘
    if 'current_data' in st.session_state['eda_state']:
        
        df = encodingdata(st.session_state['eda_state']['current_data'])
        st.session_state['eda_state']['current_data'] = df
        cols = df.select_dtypes(['int64', 'float64']).columns
    
    # ìƒê´€ ê´€ê³„ ì‹œê°í™”ë¥¼ í•  ë³€ìˆ˜ ì„ íƒ (2ê°œ ì´ìƒ)
    options = st.multiselect(
        'Select the Variables',
        cols,
        [],
        max_selections=len(cols))
    
    # ì„ íƒëœ ë³€ìˆ˜ê°€ 2ê°œ ì´ìƒì¸ ê²½ìš° figureë¥¼ ìƒì„±í•˜ì—¬ ì¶œë ¥
    if len(options)>=2:
        st.pyplot(get_corr(options, df))
        
def missing_data():
    pass

# EDA í˜ì´ì§€ ì¶œë ¥ í•¨ìˆ˜
def eda_page():
    st.title('Data Analysis')
    
    # eda page tab ì„¤ì •
    # tabsì—ëŠ” File Upload, Variables (type, na, ë¶„í¬ ë“±), Correlation(ìˆ˜ì¹˜)ì´ í¬í•¨ë©ë‹ˆë‹¤.
    t1, t2 = st.tabs(['Variables', 'Correlation'])
    
#     with t1:
#         file_uploader()
    
    with t1:
        variables()
    
    with t2:
        correlation()
        
# ë…ë¦½ ë³€ìˆ˜ ì„ íƒ ë° ë°ì´í„° ë¶„í•  í•¨ìˆ˜
def select_split():
    cols = []
    selected_features = []
    selected_label = []
    split_rate = 0
    
    # ì €ì¥ëœ dfê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‹¤í–‰
    if 'current_data' in st.session_state['eda_state']:
        df = st.session_state['eda_state']['current_data']
        cols = df.columns
    
    # ì´ë¯¸ ì €ì¥ëœ ì„ íƒëœ ë…ë¦½ ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥
    if 'selected_features' in st.session_state['modeling_state']:
        selected_features = st.session_state['modeling_state']['selected_features']

    # ì´ë¯¸ ì €ì¥ëœ ì„ íƒëœ ì¢…ì† ë³€ìˆ˜ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥
    if 'selected_label' in st.session_state['modeling_state']:
        selected_label = st.session_state['modeling_state']['selected_label']
        
    # ì´ë¯¸ ì„¤ì •ëœ ë¶„í•  ë¹„ìœ¨ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥
    if 'split_rate' in st.session_state['modeling_state']:
        split_rate = st.session_state['modeling_state']['split_rate']
    
    # ì´ë¯¸ ì„¤ì •ëœ ëœë¤ ì‹œë“œ ê°’ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥
    if 'split_rs' in st.session_state['modeling_state']:
        split_rs = st.session_state['modeling_state']['split_rs']
    
    # ë…ë¦½ ë³€ìˆ˜ ì„ íƒ
    with st.form('feature_selection'):
        selected_features = st.multiselect(
            'Select the Independent Variables',
            cols,
            selected_features,
            max_selections=len(cols))
        
        submitted = st.form_submit_button('Select')
        if submitted:
            st.session_state['modeling_state']['selected_features'] = selected_features
        st.write(f'Independent Variables: {selected_features}')
    
    # ë…ë¦½ ë³€ìˆ˜ë¡œ ì„ íƒëœ ë³€ìˆ˜ ì œì™¸
    cols = list(set(cols)-set(selected_features))
    
    # ì¢…ì† ë³€ìˆ˜ ì„ íƒ
    with st.form('label_selection'):
        selected_label = st.multiselect(
            'Select the Dependent Variables',
            cols,
            selected_label,
            max_selections=1)
        
        submitted = st.form_submit_button('Select')
        if submitted:
            st.session_state['modeling_state']['selected_label'] = selected_label
        st.write(f'Dependent Variables: {selected_label}')
    # ë¶„í•  ë¹„ìœ¨(test_size) ë° ëœë¤ ì‹œë“œ ì„¤ì •
    with st.form('Split Rate'):
        split_rate = st.slider('Test Rate', 0.1, 0.9, 0.25, 0.01)
        split_rs = st.slider('Random State', 0, 100000, 0, 1)
        
        submitted = st.form_submit_button('Confirm')
        if submitted:
            st.session_state['modeling_state']['split_rate'] = split_rate
            st.session_state['modeling_state']['split_rs'] = split_rs
        st.write(f'Train/Test Ratio â†’ Train: {(1-split_rate):.1%}, Test: {split_rate:.1%}')
        st.write(f'Random Seed: {split_rs}')

# í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì„¤ì •
def set_hyperparamters(model_name):
    param_list = {
        'Random Forest Classifier':{
            'n_estimators':[1, 3000, 100, 1], 
            'max_depth':[1, 6, 5, 1],
            'min_samples_leaf':[1, 100, 1, 1],
            'min_samples_split':[2, 100, 2, 1],
            'random_state':[0, 100000, 0, 1]},
        'Gradient Boosting Classifier' :{
            'n_estimators':[1, 2000, 100, 1],
            'max_depth':[1, 6, 5, 1],
            'min_samples_leaf':[1, 100, 1, 1],
            'min_samples_split':[2, 100, 2, 1],
            'subsample':[0.0, 1.0, 1.0, 0.01],
            'learning_rate':[0.0, 1.0, 0.1, 0.01],
            'random_state':[0, 100000, 0, 1]},
        'Extreme Gradient Boosting Classifier':{
            'n_estimators':[1, 2000, 100, 1],
            'max_depth':[1, 6, 5, 1],
            'min_child_weight':[1, 10, 1, 1],
            'subsample':[0.0, 1.0, 1.0, 0.01],
            'colsample_bytree':[0.0, 1.0, 1.0, 0.01],
            'learning_rate':[0.0, 1.0, 0.1, 0.01],
            'random_state':[0, 100000, 0, 1]}
    }
    
    ret = {}
    with st.form('hyperparameters'):
        for key, item in param_list[model_name].items():
            #             # ë§Œì•½ keyê°€ hyperparametersì— ì¡´ì¬í•œë‹¤ë©´ ì‚¬ìš©
            # if key in st.session_state['modeling_state']['hyperparamters']:
            ret[key] = st.slider(key, *item)
        
        submitted = st.form_submit_button('Run')
        
        if submitted:
            st.write(ret)
            return ret
        
# split data
def split_data():
    df = st.session_state['eda_state']['current_data']
    X = df.loc[:, st.session_state['modeling_state']['selected_features']].values
    Y = df.loc[:, st.session_state['modeling_state']['selected_label']].values.reshape(-1)
    
    test_size = st.session_state['modeling_state']['split_rate']
    seed = st.session_state['modeling_state']['split_rs']
    
    x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=seed, test_size=test_size)
    
    return x_train, x_test, y_train, y_test
       
# train_model
def train_model(selected_model, model_name):
    with st.spinner('Data Splitting...'):
        x_train, x_test, y_train ,y_test = split_data()
        time.sleep(1)
    st.success('Complete Data Splitting')
    time.sleep(1)

    with st.spinner('Learning...'): 
        model = selected_model(**st.session_state['modeling_state']['hyperparamters'])
        model.fit(x_train, y_train)
    st.success('Complete Learning')

    with st.spinner('Predicting...'):
        train_pred = model.predict(x_train)
        test_pred = model.predict(x_test)
    st.success('Complete Predicting')
    
    file_name = datetime.datetime.now().strftime('%Y%m%d%H%M%S')
    
    # ëª¨ë¸ íŒŒì¼ ì €ì¥
    with open(f'./models/model_{model_name.replace(" ", "_")}_{file_name}.dat', 'wb') as f:
        pickle.dump(model, f)
    
    # í•™ìŠµì— ì‚¬ìš©ëœ ë…ë¦½ ë³€ìˆ˜ ëª©ë¡ ì €ì¥ (ìˆœì„œ)
    with open(f'./models/meta_{model_name.replace(" ", "_")}_{file_name}.dat', 'wb') as f:
        pickle.dump(st.session_state['modeling_state']['selected_features'], f)
        
    return model, y_train, train_pred, y_test, test_pred
        
# modeling í•¨ìˆ˜
def modeling():
    # ëª¨ë¸ë§ tab ì¶œë ¥ í•¨ìˆ˜
    model_list = ['Select the Model', 'Random Forest Classifier', 'Gradient Boosting Classifier', 'Extreme Gradient Boosting Classifier']
    model_dict = {'Random Forest Classifier': RandomForestClassifier,
                  'Gradient Boosting Classifier':GradientBoostingClassifier, 
                  'Extreme Gradient Boosting Classifier':XGBClassifier }
    selected_model = ''
    
    if 'selected_model' in st.session_state['modeling_state']:
        selected_model = st.session_state['modeling_state']['selected_model']
    if 'hyperparamters' in st.session_state['modeling_state']:
        hps = st.session_state['modeling_state']['hyperparamters']

    # selected_model = st.multiselect(
    #     'Select the model for learning',
    #     model_list,
    #     [],
    #     max_selections=len(model_list))        

    selected_model = st.selectbox(
        'Select the model for learning.',
        model_list, 
        index=0)

    if selected_model in model_list[1:]:
        st.session_state['modeling_state']['selected_model'] = selected_model
        hps = set_hyperparamters(selected_model)
        st.session_state['modeling_state']['hyperparamters'] = hps
        
        if hps != None:
            model, y_train, train_pred, y_test, test_pred = train_model(model_dict[selected_model], selected_model)
            st.session_state['modeling_state']['model'] = model
            st.session_state['modeling_state']['y_train'] = y_train
            st.session_state['modeling_state']['y_test'] = y_test
            st.session_state['modeling_state']['train_pred'] = train_pred
            st.session_state['modeling_state']['test_pred'] = test_pred
            st.success('Finish Learning')
            
# Confusion Matrix í•¨ìˆ˜
def plot_confusion_matrix(y_true, y_pred, class_names):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(4, 3))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.title("Confusion Matrix")
    plt.xlabel("Predictive")
    plt.ylabel("Actual")
    st.pyplot()

# ê²°ê³¼ tab í•¨ìˆ˜
def results():
    with st.expander('Metrics', expanded=True):
        if 'y_train' in st.session_state['modeling_state']:
            st.divider()

            d1, d2 = st.columns(2)
            d1.subheader('**:green[Train Results]**')
            left = d1.columns(2)
            ac = accuracy_score(st.session_state['modeling_state']['y_train'], st.session_state['modeling_state']['train_pred'])
            d1.write(f'**:blue[Accuracy]**  :  **{ac: 10.5f}**')

            f1 = f1_score(st.session_state['modeling_state']['y_train'], st.session_state['modeling_state']['train_pred'])
            d1.write(f'**:blue[f1]**  :  **{f1: 10.5f}**')

            rc = recall_score(st.session_state['modeling_state']['y_train'], st.session_state['modeling_state']['train_pred'])
            d1.write(f'**:blue[Recall]**  :  **{rc:10.5f}**')

            pc = precision_score(st.session_state['modeling_state']['y_train'], st.session_state['modeling_state']['train_pred'])
            d1.write(f'**:blue[Precision]**  :  **{pc:10.5f}**')

        if 'y_test' in st.session_state['modeling_state']:
            st.divider()
            d2.subheader('**:green[Test Results]**')
            right = d2.columns(2)

            ac = accuracy_score(st.session_state['modeling_state']['y_test'], st.session_state['modeling_state']['test_pred'])
            d2.write(f'**:blue[Accuracy]**  :  **{ac:10.5f}**')

            f1 = f1_score(st.session_state['modeling_state']['y_test'], st.session_state['modeling_state']['test_pred'])
            d2.write(f'**:blue[f1]**  :  **{f1:10.5f}**')

            rc = recall_score(st.session_state['modeling_state']['y_test'], st.session_state['modeling_state']['test_pred'])
            d2.write(f'**:blue[Recall]**  :  **{rc:10.5f}**')

            pc = precision_score(st.session_state['modeling_state']['y_test'], st.session_state['modeling_state']['test_pred'])
            d2.write(f'**:blue[Precision]**  :  **{pc:10.5f}**')

            
    st.divider()
    with st.expander('Classification Report', expanded=False):
        if 'y_train' in st.session_state['modeling_state']:
            st.write('**:blue[0 : ìš°ì„ ê°œë°©ì¥ì¹˜, 1 : ì¼ë°˜ì¥ì¹˜]**')
            st.table(pd.DataFrame(classification_report(st.session_state['modeling_state']['y_test'], st.session_state['modeling_state']['test_pred'], output_dict=True)))
               
    st.divider()
    st.set_option('deprecation.showPyplotGlobalUse', False)
    with st.expander('Result Analysis', expanded=False):
        if 'y_train' in st.session_state['modeling_state']:
            # c1, c2 = st.columns(2)
            st.title('Train')
            plot_confusion_matrix(st.session_state['modeling_state']['y_train'],
                                  st.session_state['modeling_state']['train_pred'],
                                  ['ìš°ì„ ê°œë°©','éìš°ì„ ê°œë°©'])
            st.divider()
            st.title('Test')
            plot_confusion_matrix(st.session_state['modeling_state']['y_test'],
                                  st.session_state['modeling_state']['test_pred'],
                                  ['ìš°ì„ ê°œë°©','éìš°ì„ ê°œë°©'])
     
    st.divider()
    
    with st.expander('Feature Importances', expanded=False):
        if 'model'  in st.session_state['modeling_state']:
            plt.figure()
            plot = sns.barplot(x=st.session_state['modeling_state']['selected_features'],
                               y=st.session_state['modeling_state']['model'].feature_importances_)
            plt.title('Feature Importances')
            plt.xticks(rotation=90)
            fig = plot.get_figure()
            st.pyplot(fig, use_container_width=True)
            
# Modeling í˜ì´ì§€ ì¶œë ¥ í•¨ìˆ˜
def modeling_page():
    st.title('Machine Learning')
    
    # tabsë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
    # tabsì—ëŠ” File Upload, Variables (type, na, ë¶„í¬ ë“±), Correlation(ìˆ˜ì¹˜)ì´ í¬í•¨ë©ë‹ˆë‹¤.
    t1, t2, t3 = st.tabs(['Data Selection and Split', 'Modeling', 'Results'])

    # file upload tab êµ¬í˜„
    with t1:
        select_split()
    
    with t2:
        modeling()
    
    with t3:
        results()
        
def testfile_merging():
    # íŒŒì¼ ì—…ë¡œë” ìœ„ì ¯ ì¶”ê°€ (1ë²ˆì¨°)
    material = st.file_uploader("Please upload PSM files", type=['csv', 'xls', 'xlsx'], accept_multiple_files=True)

    if material is not None:
        # ìƒˆ íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state['serving_state'] = {}
        
        # ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
        st.session_state['serving_state']['current_file'] = material
    else:
        st.warning('Please upload PSM file')
    
    # ìƒˆë¡œ ì—…ë¡œë“œí•œ íŒŒì¼ì„ dfë¡œ ë¡œë“œ
    if 'current_data' in st.session_state['serving_state'] and len(st.session_state['serving_state']['current_data']) > 0:
        if st.session_state['serving_state']['current_data']:
            # ì²« ë²ˆì§¸ íŒŒì¼ì„ ì„ íƒ (ë¦¬ìŠ¤íŠ¸ì—ì„œ íŒŒì¼ì„ ì„ íƒí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½)
            selected_material = st.session_state['serving_state']['current_data'][0]

            # íŒŒì¼ ì´ë¦„ ì¶œë ¥
            if hasattr(selected_material, 'name'):
                st.write(f"Current File: {selected_material.name}")
            else:
                st.write("Current File: Does not have 'name' attribute")

            # ì„ íƒëœ íŒŒì¼ì„ dfë¡œ ë¡œë“œ
            st.session_state['serving_state']['current_data'] = load_file(selected_material)
            print(f"708===================={st.session_state['serving_state']['current_data']}")

    # ìƒˆë¡œ ë¡œë“œí•œ df ì €ì¥
    if 'current_data' in st.session_state['serving_state']:
        st.dataframe(st.session_state['serving_state']['current_data'])
        
    if st.session_state['serving_state']['current_data'] is not None and len(st.session_state['serving_state']['current_data']) > 0:
        # ì—…ë¡œë“œëœ íŒŒì¼ë“¤ì„ í•©ì³ì„œ DataFrameìœ¼ë¡œ ê°€ì ¸ì˜´

        combined_testdata = combinedata(st.session_state['serving_state']['current_data'])
        print(f'716--------------------{combined_testdata}')
        # # ê²°ê³¼ë¥¼ í‘œì‹œ
        st.dataframe(combined_data)

        # splitdata í•¨ìˆ˜ í˜¸ì¶œ
        df_testsplit = splitdata(combined_testdata)
        st.session_state['serving_state']['current_file'] = df_testsplit
        st.session_state['serving_state']['df_split'] = df_testsplit
    # ê²°ê³¼ë¥¼ í‘œì‹œ
        st.dataframe(df_testsplit)
        
# files ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”
    materials = []

    if 'df_split' in st.session_state['serving_state'] and len(st.session_state['serving_state']['df_split']) > 0:
        materials = st.file_uploader("Please upload EPS files", type=['csv', 'xls', 'xlsx'], accept_multiple_files=True, key="file_uploader")
    else:
        st.warning('Please upload EPS file')

        # ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if materials is not None:
            # ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            st.session_state['serving_state']['current_file'] = materials

            # ì—…ë¡œë“œëœ ê° íŒŒì¼ì„ ì½ì–´ DataFrameìœ¼ë¡œ ë³€í™˜
            dfs_testuploaded = [pd.read_excel(file, header=None) for material in materials]
            if len(dfs_testuploaded) > 0:
                df_testeps = dfs_testuploaded[0]

                st.session_state['serving_state']['current_data'] = df_testeps

                # ìƒˆë¡œ ë¡œë“œí•œ df ì €ì¥
                if 'current_data' in st.session_state['serving_state']:

                    df_testeps = df_testeps.rename(columns={0: 'ì¥ì¹˜ë²ˆí˜¸', 1: 'ì„¤ë¹„ë“±ê¸‰', 2:'ì„¤ë¹„ìœ í˜•',
                                                              6:'ë¶€ì‹ìœ¨', 7:'ì”ì—¬ìˆ˜ëª…'})
                    df_testeps[15] = np.nan
                    df_testeps[16] = np.nan
                    df_testeps['ìš°ì„ ê°œë°©ì—¬ë¶€'] = 'í•´ë‹¹ì—†ìŒ'   
                    df_testeps.columns = df_testeps.columns.astype(str)
                    st.session_state['serving_state']['eps_data'] = df_testeps

                    # df_aì™€ df_uploadedë¥¼ merge
                    df_testmerged = mergedata(st.session_state['serving_state']['eps_data'], st.session_state['serving_state']['df_split'])
                    st.session_state['serving_state']['eps_data'] = df_testmerged
                    st.dataframe(st.session_state['serving_state']['eps_data'])
                    

    if 'eps_data' in st.session_state['serving_state'] and len(st.session_state['serving_state']['eps_data']) > 0:
        materialss = st.file_uploader("Please upload EQL file", type=['csv', 'xls', 'xlsx'])

        # ì—…ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if materialss is not None:
            # ìƒˆë¡œ ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            st.session_state['serving_state']['current_equlist'] = materialss
            
        # ìƒˆë¡œ ì—…ë¡œë“œí•œ ì¥ì¹˜List íŒŒì¼ì„ dfë¡œ ë¡œë“œ
        if 'current_equlist' in st.session_state['serving_state']:
            # st.write(f"Current File_equipment list: {st.session_state['preprocessing_state']['current_equlist'].name}")
            testequlist = pd.read_excel(st.session_state['serving_state']['current_equlist'], skiprows=1, engine='openpyxl')
            st.session_state['serving_state']['equ_data'] = testequlist
            df_testfinal = insertdata(st.session_state['serving_state']['equ_data'])
            st.session_state['serving_state']['final_data'] = df_testfinal
            # st.dataframe(st.session_state['serving_state']['final_data'])
                    
        if 'final_data' in st.session_state['serving_state'] and len(st.session_state['serving_state']['final_data']) > 0:     
            df_testpre = preprocessdata(st.session_state['serving_state']['final_data'])
            st.session_state['serving_state']['complete_data'] = df_testpre
            st.session_state['serving_state']['current_file'] = st.session_state['serving_state']['complete_data']
            st.dataframe(st.session_state['serving_state']['current_file'])
    
        


#e ë°ì ë¡œë“œí•˜ë­‡
def loadtestfile(file):
        # íŒŒì¼ì´ ë¹„ì–´ ìˆëŠ”ì§€ í™•ì¸
    if file is None or file.size == 0:
        st.warning("íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜ ë˜ëŠ” ì˜ˆì™¸ ì²˜ë¦¬
    # try:
        # UTF-8ë¡œ ì‹œë„í•˜ê³  ì‹¤íŒ¨í•˜ë©´ ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„
    print(f'609-----------------------')
    df = pd.read_csv(file, encoding='utf-8')
    print(f'611-----------------------')

#     except UnicodeDecodeError:
#         # ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„ (EUC-KR, CP949 ë“±)
#         print(f'615 ì˜ˆì™¸ë°œìƒ..-----------------------')

#         df = pd.read_csv(file, encoding='euc-kr')
    print(f'613 {df}')
    return df

# ì¶”ë¡  í•¨ìˆ˜
def inference():
    model = st.session_state['serving_state']['model']
    model_name = st.session_state['serving_state']['model_name']
    model_name = model_name.removeprefix('model_').replace('_', ' ')
    
    if 'meta' in st.session_state['serving_state']:
        placeholder = ', '.join(st.session_state['serving_state']['meta'])
    else:
        placeholder = ''
    
    with st.expander('Data Upload', expanded=True):
        st.caption(model_name)

        # ìƒˆë¡œ ì—…ë¡œë“œí•œ íŒŒì¼ì„ dfë¡œ ë¡œë“œ
        if file is not None:
            st.session_state['serving_state']['current_file'] = file
            # st.write(f"Current File: {st.session_state['serving_state']['current_file'].name}")
            # st.session_state['serving_state']['current_data'] = loadtestfile(st.session_state['serving_state']['current_file'])
            # st.dataframe(st.session_state['serving_state']['current_data'])
        else:
            st.warning("You should upload file")
            # 'current_data'ê°€ ì—†ëŠ” ê²½ìš° ì—¬ê¸°ì„œ ë°˜í™˜í•˜ê±°ë‚˜ ì¶”ê°€ ì‹¤í–‰ì„ ì¤‘ë‹¨í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
            # ì˜ˆë¥¼ ë“¤ì–´ 'return' ë˜ëŠ” 'sys.exit()'ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            return
    with st.expander('Summary', expanded=False):
        if 'current_file' in st.session_state['serving_state']:
            dfa = st.session_state['serving_state']['current_file']
        # a = dfa.loc[:, st.session_state['serving_state']['selected_features']].values
        # b = dfa.loc[:, st.session_state['serving_state']['selected_label']].values.reshape(-1)
            pred = model.predict(dfa.iloc[:,1:9])
            print(pred)
            result_df = pd.concat([dfa, pd.Series(pred, name='ìš°ì„ ê°œë°©ì—¬ë¶€')], axis=1)
            result_df['ìš°ì„ ê°œë°©ì—¬ë¶€'] = result_df['ìš°ì„ ê°œë°©ì—¬ë¶€'].replace({'ìš°ì„ ê°œë°©': 'í•´ë‹¹', 'í•´ë‹¹ì—†ìŒ': 'ë¯¸í•´ë‹¹'})
            st.session_state['serving_state']['current_data'] = result_df
        
            # ê²°ê³¼ DataFrame ì¶œë ¥
            st.dataframe(result_df)
        else:
            st.warning("You should upload file")
            
    with st.expander('Result', expanded=True):
        if 'current_data' in st.session_state['serving_state']:
            # 'ìš°ì„ ê°œë°©ì—¬ë¶€' ì—´ì´ 'ìš°ì„ ê°œë°©ëŒ€ìƒ'ì¸ í–‰ë§Œ ì¶”ì¶œí•˜ì—¬ ë³„ë„ë¡œ ì •ë ¬
            prioritized_rows = result_df[result_df['ìš°ì„ ê°œë°©ì—¬ë¶€'] == 'í•´ë‹¹']

            # ì •ë ¬ëœ DataFrame ì¶œë ¥
            st.subheader('**:red[Priority Opening Fixed Equipment]**')
            st.dataframe(prioritized_rows.loc[:,['ì¥ì¹˜ë²ˆí˜¸','ìš°ì„ ê°œë°©ì—¬ë¶€']])
            st.write(f"**:blue[ì´ {len(result_df)}ê°œì˜ ì¥ì¹˜ ì¤‘ {len(prioritized_rows)}ê°œì˜ ì¥ì¹˜ê°€ ìš°ì„ ê°œë°©ëŒ€ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.]**")

# Serving í•¨ìˆ˜
def serving():    
    with st.form('select pre-trained model'):
        # ëª¨ë¸ íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
        model_paths = glob.glob('./models/model_*')
        model_paths.sort(reverse=True)
        model_list = [s.removeprefix('./models/').removesuffix('.dat') for s in model_paths]
        model_dict = {k:v for k, v in zip(model_list, model_paths)}
        model_list = ['Select Model'] + model_list

        # ì¶”ë¡ ì— ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ

        selected_inference_model = st.selectbox('Select the Model for Inference', model_list, index=0)
        checked = st.checkbox('Independent Variables Information')

        submitted = st.form_submit_button('Confirm')

        if submitted:
            st.session_state['serving_state'] = {}
            with open(model_dict[selected_inference_model], 'rb') as f_model:
                inference_model = pickle.load(f_model)
                st.session_state['serving_state']['model'] = inference_model
                st.session_state['serving_state']['model_name'] = selected_inference_model
                if checked:
                    with open(model_dict[selected_inference_model].replace('model_', 'meta_'), 'rb') as f_meta:
                        metadata = pickle.load(f_meta)
                        st.session_state['serving_state']['meta'] = metadata
                placeholder = st.empty()
                placeholder.success('Success')
                time.sleep(2)
                placeholder.empty()

    if 'model' in st.session_state['serving_state']:
        inference()
            
# Serving í˜ì´ì§€ ì¶œë ¥ í•¨ìˆ˜
def serving_page():
    st.title('Model Serving')
    
    # eda page tab ì„¤ì •
    # tabsì—ëŠ” File Upload, Variables (type, na, ë¶„í¬ ë“±), Correlation(ìˆ˜ì¹˜)ì´ í¬í•¨ë©ë‹ˆë‹¤.
    t1, t2 = st.tabs(['Test File Preprocessing', 'Model Serving'])
    
    with t1:
        testfile_merging()
    
    with t2:
        serving()



        
# session_stateì— ì‚¬ì „ sidebar_state, eda_state, modeling_state, serving_stateë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
if 'sidebar_state' not in st.session_state:
    st.session_state['sidebar_state'] = {}
    st.session_state['sidebar_state']['current_page'] = front_page
if 'preprocessing_state' not in st.session_state:
    st.session_state['preprocessing_state'] = {}
if 'eda_state' not in st.session_state:
    st.session_state['eda_state'] = {}
if 'modeling_state' not in st.session_state:
    st.session_state['modeling_state'] = {}
if 'serving_state' not in st.session_state:
    st.session_state['serving_state'] = {}
    
# sidebar ì¶”ê°€ preprocessing_page
with st.sidebar:
    st.subheader('Contents')
    b1 = st.button('Main Page', use_container_width=True)
    b2 = st.button('Preprocessing Page', use_container_width=True)
    b3 = st.button('EDA Page', use_container_width=True)
    b4 = st.button('Modeling Page', use_container_width=True)
    b5 = st.button('Serving Page', use_container_width=True)
    
if b1:
    st.session_state['sidebar_state']['current_page'] = front_page
#     st.session_state['sidebar_state']['current_page']()
    front_page()
elif b2:
    st.session_state['sidebar_state']['current_page'] = preprocessing_page
#     st.session_state['sidebar_state']['current_page']()
    preprocessing_page()    
elif b3:
    st.session_state['sidebar_state']['current_page'] = eda_page
#     st.session_state['sidebar_state']['current_page']()
    eda_page()
elif b4:
    st.session_state['sidebar_state']['current_page'] = modeling_page
#     st.session_state['sidebar_state']['current_page']()
    modeling_page()
elif b5:
    st.session_state['sidebar_state']['current_page'] = serving_page
#     st.session_state['sidebar_state']['current_page']()
    serving_page()
else:
    st.session_state['sidebar_state']['current_page']()
